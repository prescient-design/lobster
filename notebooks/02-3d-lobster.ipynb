{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b7551be",
   "metadata": {},
   "source": [
    "# 3D-Prescient Protein Language Model\n",
    "* Obtain structural embeddings of a sequence by folding the sequence -> discretizing the structure into a 3Di representation -> embed the (AA+3Di) tokens with 3D-PPLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b997c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62216d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "from shutil import which\n",
    "\n",
    "from prescient_plm.model import PrescientPMLM\n",
    "from prescient_plm.transforms import FoldseekTransform\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1096a3a",
   "metadata": {},
   "source": [
    "load the model and 3D tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a772170",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PrescientPMLM.load_from_checkpoint(\n",
    "    's3://prescient-pcluster-data/freyn6/models/pmlm/prod/2023-10-27T15-58-01.675608/epoch=13-step=469494-val_loss=1.5488.ckpt'\n",
    ")\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff1dc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"{model.num_trainable_parameters:,}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445e34fb",
   "metadata": {},
   "source": [
    "install Foldseek and add it to your conda env bin following the instructions [here](https://code.roche.com/prescient-design/manifold-sampler-pytorch/-/tree/master/prescient_plm?ref_type=heads#tokenizable-structural-descriptors-foldseek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0502eeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_path = \"/home/freyn6/miniconda3/envs/prescient-plm/bin\"\n",
    "os.environ[\"PATH\"] += os.pathsep + bin_path  # add to path to run foldseek in jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e252ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "foldseek = which(\"foldseek\")\n",
    "foldseek"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d95974c",
   "metadata": {},
   "source": [
    "### monomer\n",
    "transform a single sequence and embed it with 3D-PPLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecda8371",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_sequence = \"GYDPETGTWG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79105bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "foldseek_transform = FoldseekTransform(foldseek=foldseek,\n",
    "                                        pplm_fold_model_name=\"esmfold_v1\", \n",
    "                                       linker_length=3)  # specify if you have a dimer complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f78f078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AA single chain -> AA+3Di\n",
    "seq_dict = foldseek_transform.transform(sequences=[example_sequence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd05f60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# {\"chain id\": (AA seq, 3Di seq, AA+3Di seq)}\n",
    "seq_dict[\"A\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee286a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_3d = seq_dict[\"A\"][2]\n",
    "h = model.sequences_to_latents([tokens_3d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35774b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(h), h[-1].shape  # 9 blocks, hidden rep of dim (1024, 384)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05257aff",
   "metadata": {},
   "source": [
    "### dimer (complex)\n",
    "transform a dimer and embed it with 3D-PPLM  \n",
    "e.g., example_dimer = [Concatenated antibody Vh+Vl, Antigen sequence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba624a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_dimer = [example_sequence, example_sequence[::-1]]\n",
    "example_dimer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f3d4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimer_seq_dict = foldseek_transform.transform(sequences=[example_dimer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1665c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimer_seq_dict[\"A\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a535d553",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimer_tokens_3d = dimer_seq_dict[\"A\"][2]\n",
    "h_dimer = model.sequences_to_latents([dimer_tokens_3d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248e1821",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_dimer[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6721e9ac",
   "metadata": {},
   "source": [
    "# PDB embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fd599b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab1228b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/scratch/site/u/freyn6/data/fasta/pdb_3di_complexes.fasta') as fasta_file:\n",
    "    identifiers = []\n",
    "    sequences = []\n",
    "    for seq_record in SeqIO.parse(fasta_file, 'fasta'):\n",
    "        identifiers.append(seq_record.id)\n",
    "        sequences.append(str(seq_record.seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7e92b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b705845",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.sequences_to_latents(sequences[:5])[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4af9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3015256d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_all = model.sequences_to_latents(sequences[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6195be",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.equal(embeddings[-2], embeddings_all[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4e83bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "e0 = embeddings[-2][0]\n",
    "e1 = embeddings[-2][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0525a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "e0.shape, e1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6a6dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cos = torch.nn.CosineSimilarity(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0b0df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = cos(e0.mean(dim=1), embeddings[-2][4].mean(dim=1))\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5aec908",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prescient-plm",
   "language": "python",
   "name": "prescient-plm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
