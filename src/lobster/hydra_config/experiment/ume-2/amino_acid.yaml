# @package _global_

defaults:
  - override /data: null
  - override /callbacks: [base]
  - override /model: null
  - override /lr_scheduler: null
  # - override /hydra/launcher: submitit_slurm

compile: false

biopython_features: [
    "molecular_weight",
    "aromaticity_index",
    "instability_index",
    "isoelectric_point",
    "alpha_helix_fraction",
    "turn_structure_fraction",
    "beta_sheet_fraction",
    "molar_extinction_coefficient_reduced_cysteines",
    "molar_extinction_coefficient_oxidized_cysteines",
    "grand_average_hydropathy_index",
    "net_charge_at_ph_6",
    "net_charge_at_ph_7"
  ]


data:
  _target_: lobster.data.UMELightningDataModule
  datasets:
    - AMPLIFY
    - PeptideAtlas
  root: ${oc.env:LOBSTER_DATA_DIR}
  max_length: 1024
  seed: 0
  batch_size: 64
  pin_memory: true
  num_workers: 8
  use_shared_tokenizer: false
  dataset_kwargs:
    AMPLIFY:
      extra_transform_fns:
        biopython:
          _target_: lobster.transforms.ProteinToBioPythonFeaturesTransform
          feature_list: ${biopython_features}
          standardize: true
    PeptideAtlas:
      extra_transform_fns:
        biopython:
          _target_: lobster.transforms.ProteinToBioPythonFeaturesTransform
          feature_list: ${biopython_features}
          standardize: true

model:
  _target_: lobster.model.ume2.UMESequenceEncoderLightningModule 
  auxiliary_tasks:
    - _target_: lobster.model.ume2.AuxiliaryTask
      name: biopython
      task_type: regression
      output_dim: 12
      hidden_size: null
      loss_weight: 0.01
      pooling: mean
      num_layers: 2
      dropout: 0.1
  lr: 0.001
  scheduler: cosine
  scheduler_kwargs:
    num_warmup_steps: 5_000
    num_training_steps: 100_000
  weight_decay: 0.01
  mask_token_id: 32
  pad_token_id: 1
  special_token_ids: [0, 1, 2, 3, 32]
  mask_probability: 0.15
  ckpt_path: null 
  encoder_kwargs:
    max_length: ${data.max_length}
    cache_dir: /data2/ume/checkpoints
    model_size: small
    vocab_size: 33 # 33 for amino acids or 1280 for shared vocabulary

logger:
  name: UME-2-protein-with-aux_${paths.timestamp}
  project: lobster
  entity: ${oc.env:LOBSTER_USER}
  save_dir: ${oc.env:LOBSTER_RUNS_DIR}
  tags:
    - protein
    - pre-train
    - aa-tokenizer
    - sweep
    - cosine
    # - zero-weight-on-auxiliary-tasks
  # resume: must
  # id: wo79994t
  # allow_val_change: true

paths:
  timestamp: ${now:%Y-%m-%d}T${now:%H-%M-%S} 
  output_dir: ${paths.root_dir}/${paths.timestamp}
  root_dir: ${oc.env:LOBSTER_RUNS_DIR}

trainer:
  num_nodes: 10
  max_epochs: -1
  gradient_clip_val: 0.5
  max_time: null 
  max_steps: ${model.scheduler_kwargs.num_training_steps}
  val_check_interval: 1000
  limit_val_batches: 50_000
  precision: 16-mixed
  accumulate_grad_batches: 2
  devices: auto
  strategy: ddp_find_unused_parameters_true

callbacks:
  model_checkpoint:
    save_top_k: -1
    every_n_train_steps: ${trainer.val_check_interval}
  auxiliary_task_weight_scheduler:
    _target_: lobster.callbacks.AuxiliaryTaskWeightScheduler
    schedule_type: linear
    start_step: 80_000
    ramp_steps: 100_000
    max_weight: 0.01
    task_name: biopython
  # batch_size_finder:
  #   _target_: lightning.pytorch.callbacks.BatchSizeFinder
  #   mode: power
  #   steps_per_trial: 3
  #   init_val: 64
  #   max_trials: 25
  #   batch_arg_name: batch_size


# hydra:
#   run:
#     dir: outputs/${hydra:job.name}
#   job:
#     chdir: false
#   launcher:
#     timeout_min: 10080  # 7 days (7 * 24 * 60 = 10080 minutes)
#     cpus_per_task: 8
#     nodes: ${trainer.num_nodes}
#     tasks_per_node: 8
#     gpus_per_node: 8
#     mem_gb: 256
#     name: ${hydra.job.name}
#     partition: b200
#     qos: preempt
#     setup:
#       - "cd $SLURM_SUBMIT_DIR"
#       - "source .venv/bin/activate"
#       - "nvidia-smi"
#       - "export LD_LIBRARY_PATH=/opt/amazon/efa/lib64:/opt/amazon/openmpi/lib64:/opt/amazon/ofi-nccl/lib64"
#       - "export WANDB_BASE_URL=https://genentech.wandb.io"
#       - "export WANDB_MODE=online"
#       - "export WANDB_DIR=$SLURM_SUBMIT_DIR/wandb"
#       - "export WANDB_INSECURE_DISABLE_SSL=true"
#       - "export HYDRA_FULL_ERROR=1"
#       - "export PYTHONUNBUFFERED=1"
#       - "export NCCL_DEBUG=INFO"
#       - "export LOBSTER_RUNS_DIR=s3://prescient-lobster/ume/runs"
#       - "export LOBSTER_DATA_DIR=/data2/ume/.cache2/"
#       - "export LOBSTER_USER=$(whoami)"
#       - "export TOKENIZERS_PARALLELISM=true"
#       - "umask g+w"
