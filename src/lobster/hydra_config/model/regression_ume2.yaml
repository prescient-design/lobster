_target_: lobster.model._property_regression.PropertyRegression

# UME-2 encoder (UMESequenceEncoderModule)
# 
# Checkpoint loading behavior:
# - Critical params (vocab_size, hidden_size) are auto-inferred from checkpoint weights
# - Other params (model_size, pad_token_id, max_length) can be specified in experiment config
# - device: Auto-detects (cuda if available, else cpu). Can override in experiment config.
#
# Random initialization (model_ckpt: null):
# - Must specify all params: model_size, pad_token_id, max_length, vocab_size
encoder:
  _target_: lobster.model.ume2.UMESequenceEncoderModule
  model_ckpt: ???  # Required: set to checkpoint path or null for random init
  # cache_dir: only needed if model_ckpt is an S3 path (set in experiment config)
  # device: auto-detects by default (cuda if available, else cpu)

config:
  _target_: lobster.model._property_regression.PropertyRegressionConfig
  task_name: property
  loss_function: ${training.loss_function}  # e.g., mse, huber, smooth_l1, gaussian, exponential
  hidden_sizes: [512]
  dropout: 0.1
  activation: auto
  pooling: mean
  lr: 1e-3
  weight_decay: 0.0
